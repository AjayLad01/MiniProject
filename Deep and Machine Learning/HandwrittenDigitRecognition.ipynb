{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center> <b>Handwritten Digit Recognition - MNIST Dataset </b></center>"
      ],
      "metadata": {
        "id": "ZiJE2PZ3u6py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MNIST database:**\n",
        "\n",
        "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. - \n",
        "[Wikipedia](https://en.wikipedia.org/wiki/MNIST_database)\n"
      ],
      "metadata": {
        "id": "lV1gXMUUBYT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras:**\n",
        "\n",
        "Keras is an open-source software library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.Up until version 2.3, Keras supported multiple backends, including TensorFlow, Microsoft Cognitive Toolkit, Theano, and PlaidML.As of version 2.4, only TensorFlow is supported. Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System),and its primary author and maintainer is François Chollet, a Google engineer. Chollet is also the author of the Xception deep neural network model.\n",
        "[Wikipedia](https://en.wikipedia.org/wiki/Keras)"
      ],
      "metadata": {
        "id": "RuO9n-4GCgcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas:**\n",
        "\n",
        "pandas is a software library written for the Python programming language for data manipulation and analysis.In particular, it offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license.[Wkipedia](https://en.wikipedia.org/wiki/Pandas_(software))"
      ],
      "metadata": {
        "id": "Zm__nyDmDyFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy:**\n",
        "\n",
        "NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
        "[Wikipedia](https://en.wikipedia.org/wiki/NumPy)"
      ],
      "metadata": {
        "id": "6yh9youEEjin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matplotlib:**\n",
        "Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK. There is also a procedural \"pylab\" interface based on a state machine (like OpenGL), designed to closely resemble that of MATLAB, though its use is discouraged.SciPy makes use of Matplotlib.[Wikipedia](https://en.wikipedia.org/wiki/Matplotlib)\n"
      ],
      "metadata": {
        "id": "4U67POiHFO16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>Import the necessary libraries and modules</b></center>"
      ],
      "metadata": {
        "id": "MjV4YxHXvov6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ABd2lZ9Vj-rT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>Loading and Splitting the MNIST dataset into Train and Test</b></center>"
      ],
      "metadata": {
        "id": "fgroqOajwfdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wdznb-mkAQj",
        "outputId": "2dab6ca9-5904-477c-9d62-06aebb363c8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b></b></center>"
      ],
      "metadata": {
        "id": "YEekKBCUw1Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfJPeHdkV_a",
        "outputId": "6faf42ae-33b3-4b3c-a100-79cb094a4b4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b> Preprocessing the input data</b></center>"
      ],
      "metadata": {
        "id": "-uiV275qw3tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "5QTSHCHmkgVp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-KcGKRkj2Y",
        "outputId": "a68aa5bd-df6c-4f7e-ac84-9f0ff4b3b0f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "print(y_train.shape)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCAPfm45ko6R",
        "outputId": "939d618c-8971-45c1-d7a7-e7b2c40c2e1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "IMG_SIZE=28\n",
        "# -1 is a shorthand, which returns the length of the dataset\n",
        "x_trainr = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "x_testr = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "print(\"Training Samples dimension\", x_trainr.shape)\n",
        "print(\"Testing Samples dimension\", x_testr.shape)\n",
        "# Training Samples dimension (60000, 28, 28, 1)\n",
        "# Testing Samples dimension (10000, 28, 28, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFOtwac3qMjW",
        "outputId": "c2903e00-743e-4424-c16f-8abc70266351"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples dimension (60000, 28, 28, 1)\n",
            "Testing Samples dimension (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>Creating the model</b></center>"
      ],
      "metadata": {
        "id": "6wGmr0PJwfPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conv2D**\n",
        "\n",
        "The first layer “Conv2D” kind of assigns a filter to the input image. The parameter “input_shape” defines the width and height of the input image (28, 28). The “1” after “28, 28” stands for the channel dimensions. Since we are using a grey-scale image as input, we use “1”. If we had an RGB image, we would have to use “3”. In the end, this whole concept leads to an input shape of “28, 28, 1”.\n",
        "\n",
        "Pooling (MaxPooling2D) \n",
        "\n",
        "The second layer “MaxPooling2D” reduces our image size but keeps, sometimes even highlights the most important information. Pooling is a pretty cool concept.On the left, we can see a chunk of pixels of an image. Every single pixel is represented by a number on a grey background in this example. We can divide these pixels into four 2 by 2 sections of pixels. Now pooling begins. Pooling takes the highest value out of each 2 by 2 section. This is visually presented in the above image. We can see the 2 by 2 sections in the middle. An arrow from each section points to the highest value of each section. Those 4 highest values now form a new 2 by 2 section of pixels. Using this technique we are able to massively reduce the image size but still keep the most important information of our image. This helps our Machine Learning model finding patterns and later recognizing the digits.\n",
        "\n",
        "**Flatten**\n",
        "\n",
        "The “Flatten”-layer flattens the input. The exact logic behind this isn’t necessarily needed to understand how this model works.\n",
        "\n",
        "**Dense**\n",
        "\n",
        "The “Dense”-layer just implements an equation to our neural network. A more in-depth explanation of this layer isn’t necessary for understanding how the model works.\n",
        "\n",
        "**Activation functions**\n",
        "\n",
        "Maybe you have noticed the parameter “activation” inside the definition of some of our layers. An activation function just helps our neural network if a neuron should fire or not (=should be activated or not). You don’t need to understand artificial neurons or neural networks in general now. I will just cover the two activation function used in this project (ReLU and softmax), a more in-depth explanation would exceed the purpose of this article.\n",
        "\n",
        "**ReLU**\n",
        "\n",
        "The ReLU function is one of the most popular activation functions. It stands for “rectified linear unit”. Mathematically this function is defined as:\n",
        " y = max(0,x)\n",
        "The ReLU function returns “0” if the input is negative and is linear if the input is positive. You can see this in the visualization above.\n",
        "\n",
        "**Softmax**\n",
        "\n",
        "The softmax function is another activation function. It changes input values into values that reach from 0 to 1. Because of this, we use the softmax activation function in the last layer of our Neural Network: The Neural Network generates values from 0 to 1 as output. We can see these values as probabilities for the different labels (0–9). Using this technique, we are able to get useful outputs out of our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "1F7N-WChry-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(10,activation = 'softmax'))"
      ],
      "metadata": {
        "id": "T33XoBy2kyO5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>Training the model</b></center>"
      ],
      "metadata": {
        "id": "cNT9ki2gzlKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FEuJai9ukz2Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGKT15iEk4fj",
        "outputId": "604e8da0-5ef2-4d62-cf87-81f3b8384dda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0073 - accuracy: 0.9522\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0027 - accuracy: 0.9832\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0019 - accuracy: 0.9880\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0013 - accuracy: 0.9917\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 37s 19ms/step - loss: 0.0011 - accuracy: 0.9936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3302fdb1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>Evaluate the model\n",
        "</b></center>"
      ],
      "metadata": {
        "id": "wG_7TDeiwdhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Evaluating the accuracy on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss on 10,000 test samples\", test_loss)\n",
        "print(\"Test Accuracy on 10,000 test samples\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epdxY9_FpetH",
        "outputId": "feb897ab-c4d4-411a-c349-aa82566ce1aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 27.3386 - accuracy: 0.0992\n",
            "Test Loss on 10,000 test samples 27.33864402770996\n",
            "Test Accuracy on 10,000 test samples 0.09920000284910202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_index = 122\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print(pred.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Rc8pXgjLk5Uf",
        "outputId": "4b2b1e6e-545d-4a82-d800-1513d62d7ead"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}